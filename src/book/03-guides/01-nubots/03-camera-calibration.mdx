---
section: Guides
chapter: NUbots
title: Camera Calibration
description: Learn how to calibrate cameras.
slug: /guides/nubots/camera-calibration
---

Camera calibration is done to determine optimal parameters for the cameras, such as focal length and the transform from one camera to the other. More on camera calibration can be found on [the vision page](/system/nubots/vision).

The calibration is done in two steps. The first is creating the nbs recording and the second is using that nbs recording to find the camera parameters.

1. Change `cameratest.role` to include `support::logging::DataLogging`

   ```bash
   nuclear_role(
     # FileWatcher, ConsoleLogHandler and SignalCatcher must go first. KinematicsConfiguration usually goes after these
     # and without it many roles do not run
     extension::FileWatcher
     support::SignalCatcher
     support::logging::ConsoleLogHandler
     support::logging::DataLogging
     # This must come first as it emits config which many roles depend on (e.g. SensorFilter, WalkEngine)
     motion::KinematicsConfiguration
     support::configuration::NetworkConfiguration
     support::configuration::GlobalConfig
     platform::darwin::HardwareIO
     platform::darwin::SensorFilter
     input::Camera
     support::NUsight
     output::ImageCompressor
     support::configuration::SoccerConfig
   )
   ```

2. Build using `./b build` and then install onto a robot using `./b install n<number>`. More on building can be found on the [Getting Started page](/guides/nubots/getting-started) or the [Build System page](/system/nubots/build-system).

3. On the robot, enable compressed image recording in `config/DataLogging.yaml`. Do this by setting `message.output.CompressedImage` to `true`.

4. Ensure the Left and Right camera serial numbers are correct in their respective configuration files (`Left.yaml` and `Right.yaml`).

   The serial numbers can be retrieved by first running `lsusb` and finding the bus and device numbers for the FLIR/Point Grey cameras. Then run `lsusb -s <bus number>:<device number> -v` to find the serial numbers.

   Next you will need to figure out which is left and which is right. Change the serial number for one camera to an incorrect number (this will ensure it is not found when running cameratest). Enable compressed images in `NUsight.yaml`. Run `./cameratest` and test which camera is working, simply by covering one camera and seeing the resulting image in the NUsight vision tab. Alternatively you could unplug one camera rather than change the serial number. If the serial number is on the wrong camera configuration file, switch them.

5. Check the focus of the lenses using the NUsight vision tab. If it is not sharp, focus the camera. This involves pulling the camera out from the head, still plugged in, and loosening the three grub screws. Twist until the camera is focused.

6. Check the [transform matrix](/system/nubots/mathematics#homogeneous-transformations) from the left camera to the pitch motor (Hpc) is correct in the `Left.yaml` file. This should be the transformation matrix from the camera to the end of the rigid body, i.e. the pitch motor as used in forward kinematics. Currently this is 69.952mm in $x$, 33.795mm in $y$, 64.88mm in $z$, and a positive $y$-axis rotation. In SI units the matrix is

   $$
   \text{Hpc} = \begin{bmatrix}
   \cos(\frac{2 \pi}{180}) & 0 & \sin(\frac{2 \pi}{180}) & 0.069952 \\
   0 & 1 & 0 & 0.033795 \\
   -\sin(\frac{2 \pi}{180}) & 0 & \cos(\frac{2 \pi}{180}) & 0.06488 \\
   0 & 0 & 0 & 1 \end{bmatrix}
   $$

7. Run `./cameratest` on the robot and hold up a board as shown in the below image. There is an appropriate board in the NUbots laboratory. Move the board around to cover the robot's view over time, taking into account that the lenses have a $180^{\circ}$ field of view. Move the board around at different distances and angles.

   ![A white board with black circles in rows.](./images/calibration/asymmetric-circle-grid.svg 'Asymmetric circles grid used for calibration.')

   <Grid columns='1fr 1fr' rows="1fr 1fr" caption="Photos from the robot's cameras of a person moving around a board for camera calibration">

   ![A person holding a board in the middle of the photo](./images/calibration/board-middle.jpg)
   ![A person holding a board at the bottom of the photo](./images/calibration/board-below.jpg)
   ![A person holding a board to the left](./images/calibration/board-left.jpg)
   ![A person holding a board to the right](./images/calibration/board-right.jpg)

   </Grid>

8. Stop the binary and copy the nbs file created into the NUbots directory on your computer. Do this by running the command `scp <robot address>:<file path> .` from the NUbots directory on your computer. The file will be in the `log/cameratest/` folder on the robot. The name will correspond to the date and time it was created, according to the robot. Check on the robot first using `ls` to determine the name. The name can be changed by the command `mv <old path> <new path>`.

   The robot can be turned off at this point. The recording you just made should be on your computer in the NUbots directory. Check that it is before continuing to the next steps.

9. Run the following commands to install the dependencies of the camera calibration tool if you have not done this before

   ```bash
   sudo apt install protobuf-compiler libprotobuf-dev
   sudo -H pip3 install --upgrade pip
   sudo -H pip3 install tensorflow opencv-contrib-python ruamel.yaml
   ```

10. Calibrate the cameras by running

    ```bash
    ./b nbs calibrate_cameras <nbs file name> -c <camera config folder>
    ```

    `<nbs file name>` is the name of the nbs file you just created. `<camera config folder>` is the path to the folder with the two camera config files `Left.yaml` and `Right.yaml`. These exist in `./module/input/Camera/data/config/<robot name>/Cameras/`.

    Once the calibration is done, the values in the camera configuration files should be changed.

11. Verify these values by running vision and checking the output in NUsight.

    1. Ensure `NUsight.yaml` has enabled compressed images and vision objects.
    2. Stand the robot up with `./scriptrunner Stand.yaml`
    3. Face the robot towards a straight horizontal line, such as a line of bricks on a brick wall.
    4. Run `visualmesh.role` and switch to the vision tab in NUsight

    NUsight should show a blue horizontal line, drawn at a constant height along the wall. If this is the case, then the calibration is verified.

12. Commit these changes in a new branch on GitHub to ensure they are not lost. If you are calibrating cameras on other robots, repeat the process with them. Once the calibration is complete, commit all changes and push to the branch. Make a pull request to get the changes into the master branch.
