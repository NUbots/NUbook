---
section: Guides
chapter: Main Codebase
title: Maintaining Subsystems
description: How to maintain subsystems within the main codebase.
slug: /guides/main/maintaining-subsystems
---

This page details how to maintain various subsystems within the main codebase.

## Vision

Before vision can work on the robot, odometry and kinematics must work on the robot. If these are inaccurate, then the green horizon is inaccurate.

### Dataset Generation

Synthetic and semi-synthetic training data for vision can be generated using NUpbr and NUgan. Pre-generated datasets for training the Visual Mesh can be found on the <abbr title="Network-Attached Storage">NAS</abbr> in the lab.

#### NUpbr

NUpbr is a Physically Based Rendering tool created in Blender. It creates semi-synthetic images with corresponding segmentation images for training.

Find out how to get and use NUpbr on the [NUpbr NUbook page](/system/tools/nupbr) and the [GitHub repository](https://github.com/NUbots/NUpbr).

#### Setting Up The Data

The [Visual Mesh repository](https://github.com/Fastcode/VisualMesh) contains information on how to set up the datasets. It contains [a script](https://github.com/Fastcode/VisualMesh/blob/master/training/build_dataset.py) that takes data and converts it into the tfrecord format that the Visual Mesh expects. The script requires a folder of raw images, segmentation masks, and metadata. NUpbr will provide all these as output, and such data can be found on the NAS. If using output from NUgan, use the corresponding NUpbr segmentation masks and metadata, and add the generated NUgan images to the image folder.

### The Visual Mesh

#### Training and Testing

Go to the [NUbook Visual Mesh Getting Started guide](/guides/tools/visualmesh) to find out how to train and test a network, with an example dummy dataset.

#### Exporting Configuration

The weights and biases will be output into a yaml file like the one found at [model.yaml on the Visual Mesh repository](https://github.com/Fastcode/VisualMesh/blob/master/example/model.yaml) or [VisualMesh.yaml on the NUbots repository](https://github.com/NUbots/NUbots/blob/master/module/vision/VisualMesh/data/config/VisualMesh.yaml).

Replace the NUbots repository `VisualMesh.yaml` configuration with the configuration you just obtained from training the Visual Mesh. Ensure you create a new branch so you can make a PR and get any changes merged in. For further information about Git, view the [Git Guide](/guides/general/git).

### Camera Calibration

If the cameras are not calibrated correctly, the vision system will not work well. Information on calibration is available on [the input page](/system/subsystems/input).

An automatic camera calibration tool is available to use in the NUbots repository that can be used to calibrate the cameras. A guide on how to calibrate the cameras will be available on NUbook soon.

### Testing

Now that the Visual Mesh has been updated in the NUbots repository, you should test it before merging.

Build the code, ensuring `ROLE_visualmesh` is set to `ON` in `./b configure -i`. Go to the [Getting Started page](/guides/main/getting-started) to find out more on how to build the code and install onto a robot. Ensure the new configuration file has been installed. Check out the [Build System page](/system/foundations/build-system) to find out more about options when installing onto the robot.

When your new Visual Mesh is installed onto the robot, connect to the robot and ensure NUsight is on.

```sh
nano config/NUsight.yaml
```

Turn `vision object` and `compressed images` on. Run NUsight using `yarn prod` and navigate to the NUsight page in your browser. More on NUsight can be found on [the NUsight page](/system/tools/nusight).

Run the visualmesh role

```sh
./visualmesh
```

Wait for the cameras to load and then watch the Vision tab in NUsight. To determine if the output is correct, consult the [vision page](/system/subsystems/vision) for images of the expected output.

If you would like to see the visual mesh output in NUsight, you will need to log the data and run it back in NUsight using DataPlayback, since the data is too large to send over a network. Add into the `visualmesh.role` file `support::logging::DataLogging`. Build to the robot and rerun the visual mesh binary with `./visualmesh`. An NBS file will be created on the robot in `logs/visualmesh/`. Copy this across the network to the computer you built on using `scp <robot_address>:logs/visualmesh/<file_name> ./recordings` on the computer in the NUbots folder. Read [the Logging page](/system/subsystems/logging) to find out how to play an NBS file back.

If the output has improved, create a PR and get the changes merged in to the GitHub repository. For further information about Git, view the [Git Guide](/guides/general/git).
